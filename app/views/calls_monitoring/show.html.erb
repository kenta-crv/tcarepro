<div class="container mt-4">
  <div class="row">
    <div class="col-md-8">
      <h1>Live Call Monitoring</h1>
      <h3>Call ID: <%= @call_sid %></h3>
      
      <% if @customer %>
        <div class="card mb-4">
          <div class="card-header">
            Customer Information
          </div>
          <div class="card-body">
            <p><strong>Company:</strong> <%= @customer.company %></p>
            <p><strong>Phone:</strong> <%= @customer.tel %></p>
            <p><strong>Address:</strong> <%= @customer.address %></p>
          </div>
        </div>
      <% end %>
      
      <div class="card">
        <div class="card-header">
          Audio Stream
        </div>
        <div class="card-body">
          <div id="audio-status" class="alert alert-info">
            Connecting to call stream...
          </div>
          
          <div class="volume-control mt-3">
            <label for="volume">Volume:</label>
            <input type="range" id="volume" min="0" max="1" step="0.1" value="0.5">
          </div>
          
          <div class="mt-3">
            <canvas id="audio-visualizer" width="600" height="100"></canvas>
          </div>
          
          <div class="call-info mt-3">
            <p><strong>Connected:</strong> <span id="connected-time"><%= @call_info[:connected_at].strftime("%H:%M:%S") %></span></p>
            <p><strong>Duration:</strong> <span id="call-duration">0:00</span></p>
          </div>
        </div>
      </div>
      
      <div class="mt-3">
        <%= link_to "Back to Call List", calls_monitoring_index_path, class: "btn btn-secondary" %>
      </div>
    </div>
    
    <div class="col-md-4">
      <div class="card mb-4">
        <div class="card-header">
          Live Transcript
        </div>
        <div class="card-body">
          <div id="live-transcript" class="transcript-container">
            <p class="text-muted">Waiting for transcript...</p>
            <div id="interim-text" class="interim"></div>
          </div>
        </div>
      </div>

      <div class="card">
        <div class="card-header">
          Call Events
        </div>
        <div class="card-body">
          <div id="call-events" class="call-events-log">
            <div class="event">
              <span class="time"><%= Time.current.strftime("%H:%M:%S") %></span>
              <span class="message">Monitoring started</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<style>
  .call-events-log {
    height: 400px;
    overflow-y: auto;
    font-family: monospace;
    font-size: 0.9rem;
    background: #f8f9fa;
    padding: 10px;
    border-radius: 4px;
  }
  
  .event {
    margin-bottom: 5px;
    border-bottom: 1px solid #eee;
    padding-bottom: 5px;
  }
  
  .time {
    color: #007bff;
    margin-right: 10px;
  }
  
  #audio-visualizer {
    width: 100%;
    background: #f8f9fa;
    border-radius: 4px;
  }
  
  .transcript-container {
    height: 300px;
    overflow-y: auto;
    background-color: #f8f9fa;
    padding: 15px;
    border-radius: 4px;
    font-family: 'Courier New', monospace;
  }
  
  .interim {
    color: #6c757d;
    font-style: italic;
  }
  
  .final {
    color: #212529;
  }
  
  .speaker-agent {
    color: #007bff;
    font-weight: bold;
  }
  
  .speaker-customer {
    color: #28a745;
    font-weight: bold;
  }
</style>

<script>
  $(function() {
    const callId = '<%= @call_sid %>';
    let audioContext, analyser, audioData, gainNode;
    let audioQueue = [];
    let isPlaying = false;
    let startTime = new Date();
    let transcriptBuffer = '';
    let audioInitialized = false;
    
    // Initialize ActionCable connection
    const cable = ActionCable.createConsumer();
    
    // Subscribe to audio and transcript channel (TwilioMediaChannel streams from both)
    const mediaChannel = cable.subscriptions.create(
      {
        channel: 'TwilioMediaChannel',
        call_sid: callId
      },
      {
        connected() {
          console.log('Media channel connected');
          $('#audio-status').text('Connected. Waiting for audio stream...');
          addEvent('Media channel connected');
          // Auto-initialize audio when connected
          initAudio();
        },
        
        disconnected() {
          console.log('Media channel disconnected');
          $('#audio-status').text('Connection lost. Reconnecting...');
          addEvent('Media channel disconnected');
        },
        
        received(data) {
          console.log('Received data:', data);
          
          // Handle audio data
          if (data.audio) {
            handleAudioData(data.audio);
          }
          
          // Handle transcript data
          if (data.transcript !== undefined && data.transcript !== null) {
            updateTranscript(data.transcript, data.is_final || false);
          }
        }
      }
    );
    
    function initAudio() {
      if (audioInitialized) return;
      
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        audioData = new Uint8Array(analyser.frequencyBinCount);
        
        // Create gain node for volume control
        gainNode = audioContext.createGain();
        gainNode.gain.value = parseFloat($('#volume').val()) || 0.5;
        
        analyser.connect(gainNode);
        gainNode.connect(audioContext.destination);
        
        // Start processing audio queue
        isPlaying = true;
        audioInitialized = true;
        processAudioQueue();
        
        // Start visualizer
        visualize();
        
        // Update duration timer
        setInterval(updateDuration, 1000);
        
        $('#audio-status').text('Audio streaming active');
        addEvent('Audio playback started automatically');
      } catch (e) {
        console.error('Audio initialization error:', e);
        $('#audio-status').text('Error initializing audio: ' + e.message);
        addEvent('Error initializing audio: ' + e.message);
      }
    }
    
    function handleAudioData(base64Audio) {
      if (!audioInitialized) {
        initAudio();
      }
      
      try {
        // Decode base64 to binary
        const binaryString = atob(base64Audio);
        const audioBytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
          audioBytes[i] = binaryString.charCodeAt(i);
        }
        
        // Convert μ-law to PCM
        const pcmData = convertMulawToPCM(audioBytes);
        
        // Add to queue
        audioQueue.push(pcmData);
        
        // Process if not already processing
        if (isPlaying && audioQueue.length > 0) {
          processAudioQueue();
        }
        
        $('#audio-status').text('Receiving audio stream...');
      } catch (e) {
        console.error('Error handling audio data:', e);
      }
    }
    
    function convertMulawToPCM(mulawData) {
      // μ-law to PCM conversion
      const pcmData = new Int16Array(mulawData.length);
      for (let i = 0; i < mulawData.length; i++) {
        let mulaw = mulawData[i];
        mulaw = ~mulaw;
        let sign = mulaw & 0x80;
        let exponent = (mulaw >> 4) & 0x07;
        let mantissa = mulaw & 0x0F;
        let sample = mantissa << (exponent + 3);
        sample += 0x84 << exponent;
        if (sign !== 0) sample = -sample;
        pcmData[i] = sample;
      }
      return pcmData;
    }
    
    function processAudioQueue() {
      if (!isPlaying || audioQueue.length === 0 || !audioContext) return;
      
      const pcmData = audioQueue.shift();
      
      // Create audio buffer
      const sampleRate = 8000; // Twilio uses 8kHz
      const buffer = audioContext.createBuffer(1, pcmData.length, sampleRate);
      const channelData = buffer.getChannelData(0);
      
      // Normalize PCM data to -1.0 to 1.0 range
      for (let i = 0; i < pcmData.length; i++) {
        channelData[i] = pcmData[i] / 32768.0;
      }
      
      // Play the buffer
      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(analyser);
      source.start(0);
      
      // Process next chunk
      source.onended = () => {
        if (audioQueue.length > 0) {
          processAudioQueue();
        }
      };
    }
    
    function updateTranscript(transcript, isFinal) {
      if (!transcript || transcript.trim() === '') return;
      
      // Remove "Waiting for transcript..." message
      if ($('#live-transcript p.text-muted').length > 0) {
        $('#live-transcript').html('<div id="interim-text" class="interim"></div>');
      }
      
      if (isFinal) {
        // Add the final transcript to the buffer
        transcriptBuffer += formatTranscriptLine(transcript);
        $('#live-transcript').html(transcriptBuffer + '<div id="interim-text" class="interim"></div>');
        addEvent('Transcript updated: ' + transcript.substring(0, 50) + '...');
      } else {
        // Update the interim transcript
        $('#interim-text').html(transcript);
      }
      
      // Auto-scroll to the bottom
      const container = document.getElementById('live-transcript');
      container.scrollTop = container.scrollHeight;
    }
    
    function formatTranscriptLine(text) {
      // Simple speaker detection (can be improved)
      if (text.match(/^agent:/i) || text.match(/^rep:/i) || text.match(/^representative:/i)) {
        return `<p><span class="speaker-agent">Agent:</span> ${text.replace(/^agent:|^rep:|^representative:/i, '').trim()}</p>`;
      } else if (text.match(/^customer:/i) || text.match(/^caller:/i) || text.match(/^client:/i)) {
        return `<p><span class="speaker-customer">Customer:</span> ${text.replace(/^customer:|^caller:|^client:/i, '').trim()}</p>`;
      } else {
        return `<p>${text}</p>`;
      }
    }
    
    function visualize() {
      const canvas = document.getElementById('audio-visualizer');
      const canvasCtx = canvas.getContext('2d');
      const width = canvas.width;
      const height = canvas.height;
      
      function draw() {
        requestAnimationFrame(draw);
        
        if (!analyser) return;
        
        analyser.getByteTimeDomainData(audioData);
        
        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
        canvasCtx.fillRect(0, 0, width, height);
        
        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';
        canvasCtx.beginPath();
        
        const sliceWidth = width / audioData.length;
        let x = 0;
        
        for (let i = 0; i < audioData.length; i++) {
          const v = audioData[i] / 128.0;
          const y = v * height / 2;
          
          if (i === 0) {
            canvasCtx.moveTo(x, y);
          } else {
            canvasCtx.lineTo(x, y);
          }
          
          x += sliceWidth;
        }
        
        canvasCtx.lineTo(width, height / 2);
        canvasCtx.stroke();
      }
      
      draw();
    }
    
    function updateDuration() {
      if (!isPlaying) return;
      
      const now = new Date();
      const diff = Math.floor((now - startTime) / 1000);
      const minutes = Math.floor(diff / 60);
      const seconds = diff % 60;
      
      $('#call-duration').text(`${minutes}:${seconds.toString().padStart(2, '0')}`);
    }
    
    function addEvent(message) {
      const now = new Date();
      const timeStr = now.toTimeString().split(' ')[0];
      
      $('#call-events').prepend(`
        <div class="event">
          <span class="time">${timeStr}</span>
          <span class="message">${message}</span>
        </div>
      `);
    }
    
    // Volume control
    $('#volume').on('input', function() {
      if (gainNode) {
        gainNode.gain.value = parseFloat($(this).val());
      }
    });
    
    // Clean up when leaving the page
    $(window).on('beforeunload', function() {
      if (mediaChannel) {
        mediaChannel.unsubscribe();
      }
      
      if (audioContext) {
        audioContext.close();
      }
    });
  });
</script>
