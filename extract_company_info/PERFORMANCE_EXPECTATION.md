# パフォーマンス想定と現状分析

## 1件当たりの処理時間の想定

### 現在の実装での想定時間

**理想的なケース（URL候補1個）**:
- ノード1（URL候補取得）: 約5-10秒
  - Google Search API呼び出し: 3-4秒
  - URL到達可能性チェック: 1-2秒（1個）
  - 待機時間: 3秒
- ノード2（公式サイト選定）: 0秒（スキップ）
- ノード3（会社情報抽出）: 約5-7秒
  - クロール: 2-3秒
  - API呼び出し: 2-3秒
- **合計: 約10-17秒**

**複数URL候補がある場合（URL候補6個）**:
- ノード1（URL候補取得）: 約10-15秒
  - Google Search API呼び出し: 3-4秒
  - URL到達可能性チェック: 6-10秒（6個 × 1-2秒/個）
  - 待機時間: 3秒
- ノード2（公式サイト選定）: 約20-120秒
  - 各URLを順次クロール: 6個 × 2-20秒/個 = 12-120秒
  - API呼び出し: 2-3秒
  - 待機時間: 2秒
- ノード3（会社情報抽出）: 約5-7秒
  - クロール: 2-3秒
  - API呼び出し: 2-3秒
- **合計: 約35-142秒（最悪で2分以上）**

### 実際の処理時間（ログより）

- **最短**: 約10秒（URL候補0-1個）
- **平均**: 約20-40秒（URL候補1-2個）
- **最長**: 約50-60秒（URL候補6-10個）

## 1件あたりに見ているサイト数

### 実際のURL候補数の分布（ログより）

- **0個**: 89回（約35%）
- **1個**: 138回（約54%）← 最多
- **2個**: 17回（約7%）
- **3個**: 5回（約2%）
- **4個**: 5回（約2%）
- **5個**: 1回（約0.4%）
- **6個**: 5回（約2%）
- **7個**: 2回（約0.8%）
- **9個**: 1回（約0.4%）
- **10個**: 1回（約0.4%）

**平均**: 約1.2個/件

### 各ノードで見ているサイト数

1. **ノード1（URL候補取得）**: 
   - 取得したURL候補: 平均1-2個（最大10個）
   - 最終URL候補（到達可能性チェック後）: 平均0-1個（最大6個）

2. **ノード2（公式サイト選定）**:
   - URL候補が1個以下の場合: スキップ（0個）
   - URL候補が2個以上の場合: 全てのURLをクロール（最大6個）

3. **ノード3（会社情報抽出）**:
   - 選定されたURL: 1個のみ

## 問題点

### 1. URL候補が複数ある場合の処理時間が長すぎる ⚠️⚠️

- URL候補が6個ある場合、`node_select_official_website`で**6個全てを順次クロール**
- 各URLのクロールタイムアウトが20秒のため、最悪で**120秒（2分）**かかる
- 実際のログでも、URL候補が6個の場合、ノード2の処理時間が**35.72秒**かかっている

### 2. クロールのタイムアウトが長すぎる ⚠️

- `node_select_official_website`: 20秒/URL
- `node_fetch_html`: 30秒/URL
- 実際のクロールは2-3秒で完了することが多いため、タイムアウトが長すぎる

### 3. 並列処理していない ⚠️

- URL到達可能性チェック: 順次実行
- URLクロール: 順次実行
- 並列処理すれば、処理時間を大幅に短縮できる

## 推奨される改善策

### 1. クロールのタイムアウトを短縮 ✅ 推奨

```python
# node_select_official_website
markdown = crawl_markdown(url, timeout=10)  # 20秒 → 10秒

# node_fetch_html
web_context = crawl_markdown(url, depth=0, timeout=10)  # 30秒 → 10秒
```

### 2. URL候補数の上限を設定 ✅ 推奨

```python
# 最大5個までに制限
state.urls = state.urls[:5]
```

### 3. 並列処理の実装 ✅ 推奨（将来的に）

- `concurrent.futures.ThreadPoolExecutor`を使用
- URL到達可能性チェックとクロールを並列実行

### 4. 早期終了の実装 ✅ 推奨

- 最初の1-2個のURLで十分な情報が得られた場合、残りをスキップ

